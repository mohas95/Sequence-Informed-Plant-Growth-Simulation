{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ee403f-9e84-4251-b529-7660b620e4d3",
   "metadata": {},
   "source": [
    "## *Important note\n",
    "Please ensure that you installed all the required python pip libraries as described in the REAME.md File.\n",
    "- It is recommended to create a virtual environment and install pip environment using the following command:\n",
    "\n",
    "```bash\n",
    "pip install -r pip_requirements.txt\n",
    "```\n",
    "- Alteratively, you can install all required pip libraries individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6850313f-1ef5-4464-b8c1-834cebd1dd36",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4227c-36c8-4c23-abd1-9ad948c7e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from utils import GardynDataset, envDataset, tensor_toImage, initiate_dir, save_model_config, load_model_config, imshow_batch, denormalize_image_tensor, normalize_image_tensor,calculate_fid, save_metrics, images_to_video\n",
    "torch.set_printoptions(precision=4, threshold=10, edgeitems=10, linewidth=100)\n",
    "from scipy import linalg\n",
    "from PIL import Image\n",
    "from models import SI_PGS, SI_PGS_R, cGAN\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, threshold=10, edgeitems=10, linewidth=100, suppress=True)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import gc\n",
    "\n",
    "import time, datetime, pytz\n",
    "str_format = '%Y%m%d%H%M%S'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Available Device: {device}')\n",
    "feature_encoder=False #Do not change this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb817ee-458f-4cba-b8aa-3214e465ea0b",
   "metadata": {},
   "source": [
    "# USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbe56d-98e4-44c4-99f2-0fe4d2a4853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## User input\n",
    "output_dir = './output/'\n",
    "input_file = './example_data.csv' ## path to CSV File with environmental data as inputs\n",
    "trial_name = 'test1' #name this run or outputs will be overwritten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde8dae-ce72-4e05-8d8c-be3a05dcd9b4",
   "metadata": {},
   "source": [
    "### Uncomment the model you would like to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1820deb-c16b-47be-bc1b-763b2b61cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment this section for SI-PGS\n",
    "\n",
    "model = 'SI-PGS'\n",
    "feature_encoder, generator, discriminator= SI_PGS(beta='0.75', device=device) # available beta = 0.25, 0.50, 0.75. 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac512e-3f1f-465d-8813-85c03ca98882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment this section for SI-PGS\n",
    "\n",
    "# model = 'SI-PGS-R'\n",
    "# feature_encoder, generator, discriminator= SI_PGS_R(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04d112-3d7d-46f1-986b-e5b430973578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment this section for cGAN\n",
    "\n",
    "# model = 'cGAN'\n",
    "# generator, discriminator= cGAN(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a1724f-8398-4f89-b9ba-35c70a47ea3c",
   "metadata": {},
   "source": [
    "##  Restart Kernel and Run all Cells! \n",
    "\n",
    "Click this button above\n",
    "\n",
    "![](./figures/restartandrun.png)\n",
    "\n",
    "Your results will be saved in the output folder that you specified under the trial name!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd465c-74d1-406b-af20-4ac84abd1355",
   "metadata": {},
   "source": [
    "# Load data (Do not change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf58aa2-51b3-435f-92fe-80792e2db7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Paths\n",
    "initiate_dir(output_dir)\n",
    "\n",
    "##Output directories\n",
    "sim_out_dir = f'{output_dir}{trial_name}_simulated_output/'\n",
    "initiate_dir(sim_out_dir, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de68c67-15fe-44f8-a8fe-bdf7d9b55b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = envDataset(f'{input_file}', normalized =True, cumulative = True, params = ['Temperature_C', 'Humidity_percent', 'EC', 'PH', 'WaterTemp_C'])\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=1, shuffle=False)\n",
    "dataiter = iter(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d159c8-f2ca-45d8-8d10-827eef5e5a1b",
   "metadata": {},
   "source": [
    "# Run the model (Do not change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f911e7-a979-42f4-96c2-67837fb10fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'SI-PGS':\n",
    "    with torch.no_grad():\n",
    "        i=0\n",
    "        z_cs = torch.randn(1,generator.latent_size).to(device)\n",
    "        \n",
    "        feature_encoder.eval(), generator.eval(), discriminator.eval()\n",
    "        for label, sequence_length, ts in tqdm(data_loader):\n",
    "            \n",
    "            label = label.to(device)\n",
    "            \n",
    "            ## Encoder sequential feature data\n",
    "            feature_embedding = feature_encoder(label, sequence_length)\n",
    "    \n",
    "            y_hat = generator.decode(z_cs, feature_embedding)\n",
    "    \n",
    "            y_out = y_hat[0].detach().cpu().numpy()\n",
    "                \n",
    "            img = np.transpose(y_out, (1, 2, 0))\n",
    "            img = Image.fromarray((img*255).astype(np.uint8))\n",
    "            img.save(f'{sim_out_dir}{i}.jpg')\n",
    "    \n",
    "            i+=1\n",
    "            \n",
    "elif model == 'SI-PGS-R':\n",
    "    img_path = './first_frame.jpg'\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  # Convert PIL images to tensors\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image_normalized_prior  = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        i=0\n",
    "        z_cs = torch.randn(1,generator.latent_size).to(device)\n",
    "        ts_prior = torch.tensor(0)\n",
    "        \n",
    "        feature_encoder.eval(), generator.eval(), discriminator.eval()\n",
    "        for label, sequence_length, ts in tqdm(data_loader):\n",
    "\n",
    "            time_diff = ts - ts_prior\n",
    "            time_diff = time_diff.unsqueeze(1).to(device)\n",
    "            \n",
    "            label = label.to(device)\n",
    "            \n",
    "            ## Encoder sequential feature data\n",
    "            feature_embedding = feature_encoder(label, sequence_length)\n",
    "    \n",
    "            y_hat = generator.decode(z_cs, feature_embedding,image_normalized_prior, time_diff)\n",
    "    \n",
    "            y_out = y_hat[0].detach().cpu().numpy()\n",
    "\n",
    "            image_normalized_prior = normalize_image_tensor(y_hat)\n",
    "            ts_prior = ts\n",
    "                \n",
    "            img = np.transpose(y_out, (1, 2, 0))\n",
    "            img = Image.fromarray((img*255).astype(np.uint8))\n",
    "            img.save(f'{sim_out_dir}{i}.jpg')\n",
    "    \n",
    "            i+=1\n",
    "\n",
    "elif model == 'cGAN':\n",
    "\n",
    "    data = envDataset(f'{input_file}', normalized =True, cumulative = False, params = ['Temperature_C', 'Humidity_percent', 'EC', 'PH', 'WaterTemp_C'])\n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size=1, shuffle=False)\n",
    "    dataiter = iter(data_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        i=0\n",
    "        noise = torch.randn(1,generator.noise_dim, device=device)\n",
    "        \n",
    "        generator.eval(), discriminator.eval()\n",
    "        for label, ts in tqdm(data_loader):\n",
    "            \n",
    "            label = label.to(device)    \n",
    "            y_hat = generator(noise, label)\n",
    "    \n",
    "            y_out = y_hat[0].detach().cpu().numpy()\n",
    "                \n",
    "            img = np.transpose(y_out, (1, 2, 0))\n",
    "            img = Image.fromarray((img*255).astype(np.uint8))\n",
    "            img.save(f'{sim_out_dir}{i}.jpg')\n",
    "    \n",
    "            i+=1\n",
    "\n",
    "else:\n",
    "    print('invalid Model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d4c0b-2675-4256-9a02-7507deec2db3",
   "metadata": {},
   "source": [
    "## Save Video (Do not change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12237abd-c283-443d-b073-881bfe645c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_video(sim_out_dir, f'{output_dir}{trial_name}.mp4',120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
